# Async Telemetry Gateway

A production-ready async Rust application demonstrating all major Tokio primitives working together in a realistic telemetry ingestion system.

## ğŸ¯ Overview

This telemetry gateway simulates a real-world IoT system that collects sensor data from multiple devices, aggregates it, stores it in batches, and broadcasts real-time updates to connected clients. It showcases how different async primitives solve specific architectural challenges.

## ğŸš€ Features

- **Multi-device simulation** - 7 concurrent sensor devices sending temperature/humidity data
- **Real-time aggregation** - Central hub processing and maintaining running averages
- **Batch storage** - Efficient database writes with configurable batch sizes
- **Live client updates** - 4 concurrent clients receiving real-time broadcasts
- **Graceful shutdown** - Clean termination of all concurrent tasks
- **Backpressure handling** - Bounded channels prevent memory overflow
- **Resource management** - Semaphore-controlled bandwidth and connection pooling

## ğŸ”§ Async Primitives Demonstrated

| Primitive | Usage | Purpose |
|-----------|-------|---------|
| `mpsc::channel` | Deviceâ†’Aggregator, Aggregatorâ†’Storage | Fan-in data collection, batching pipeline |
| `broadcast::channel` | Aggregatorâ†’Clients | Real-time updates to multiple subscribers |
| `watch::channel` | System state sharing | Consistent snapshots across components |
| `Semaphore` | Device bandwidth, DB connections | Resource contention control |
| `Notify` | Shutdown coordination | Cross-component signaling |
| `JoinSet` | Task management | Structured concurrency and cleanup |
| `tokio::select!` | Event handling | Multiple async operations per task |

## ğŸ“Š System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Device 1  â”‚â”€â”€â”€â–¶â”‚              â”‚â”€â”€â”€â–¶â”‚   Storage   â”‚
â”‚   Device 2  â”‚â”€â”€â”€â–¶â”‚  Aggregator  â”‚â”€â”€â”€â–¶â”‚   Writer    â”‚
â”‚   Device N  â”‚â”€â”€â”€â–¶â”‚              â”‚â”€â”€â”€â–¶â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼ (broadcast)
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Client 1   â”‚
                   â”‚  Client 2   â”‚
                   â”‚  Client N   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Quick Start

### Prerequisites
- Rust 1.70+ with Cargo
- Windows/Linux/macOS

### Build & Run
```bash
# Clone and navigate
cd async-sensor-hub

# Build optimized release
cargo build --release

# Run the telemetry gateway
cargo run --release
```

The system runs for 10 seconds, demonstrating all async patterns with structured logging output.

## ğŸ“ˆ Expected Output

```
ğŸš€ Starting Telemetry Gateway
ğŸ“Š Watch for device backpressure, storage batching, and client updates

ğŸ“± Device 1 sent: temp=20.3Â°C, humidity=55.7%
ğŸ”„ Aggregator processed telemetry from device 1
ğŸ“¡ Broadcasted update to 4 clients
ğŸ‘¤ Client 1 received update: 1 devices active, avg temps: 20.3Â°C
ğŸ’¾ Writing batch 1 (1 records) to storage
```

## ğŸ”§ Configuration

All system parameters are centralized in `src/config.rs`:

```rust
pub const TELEMETRY_CHANNEL_CAPACITY: usize = 50;    // Deviceâ†’Aggregator
pub const STORAGE_CHANNEL_CAPACITY: usize = 10;      // Aggregatorâ†’Storage  
pub const BROADCAST_CAPACITY: usize = 100;           // Real-time updates
pub const STORAGE_BATCH_SIZE: usize = 10;            // Batch optimization
pub const DEVICE_BANDWIDTH_LIMIT: usize = 3;         // Concurrent sends
```

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ main.rs         # Orchestration & graceful shutdown
â”œâ”€â”€ config.rs       # Centralized configuration
â”œâ”€â”€ types.rs        # Data structures
â”œâ”€â”€ device.rs       # Sensor simulation
â”œâ”€â”€ aggregator.rs   # Central processing hub
â”œâ”€â”€ storage.rs      # Batch storage writer
â”œâ”€â”€ client.rs       # Real-time subscribers
â””â”€â”€ metrics.rs      # System metrics framework
```

## ğŸ“ Learning Outcomes

This project demonstrates:

- **Channel Selection**: When to use mpsc vs broadcast vs watch
- **Backpressure Design**: How bounded channels create natural flow control
- **Resource Management**: Semaphore patterns for realistic constraints
- **Structured Concurrency**: JoinSet for clean task lifecycle management
- **Error Handling**: Graceful degradation and recovery patterns
- **Configuration Management**: Centralized, maintainable system parameters

## ğŸ“ Blog Post

See `blog.md` for a detailed technical explanation of how these async primitives work together in real-world systems.

## ğŸ” Key Metrics

During a typical 10-second run:
- **~40 telemetry records** processed
- **5 storage batches** written
- **4 concurrent clients** served
- **Zero data loss** with bounded channels
- **Clean shutdown** of all 13 tasks

## ğŸ“„ License

MIT License - see LICENSE file for details.